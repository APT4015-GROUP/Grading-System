Project Background:
Educational institutions need more efficient grading methods for growing class sizes and complex evaluation needs. Traditional assessment approaches often result in delayed, inconsistent, and subjectively biased grading, negatively impacting student learning experiences and institutional effectiveness. This system plans to address these challenges by leveraging a Large Language Model (LLM) to support automated, transparent, and accurate evaluation of student scripts. It also includes other features necessary for educational institutions such as plagiarism detection, duplicate submissions handling, and detailed feedback, ultimately reducing educators' workload while improving the overall quality of student assessment.


Baseline:
The current version of the system includes functions that allow teachers to publish assignments, allows students to view, upload, and submit assignments, and allows students to immediately view evaluation details for each of their submissions such as:
- Score for each question
- Total score
- Plagiarism score

However, certain features that are necessary for the system to become viable within an educational institution are missing in the current version such as admin management features:
- Uppdating assignment details
- Deleting assignments
- Viewing submissions and evaluations
- Overriding scores
- Other administrative features

There are also other aspects of the system that need improvement in order to properly support educational instituions including:
- Accuracy of evaluation scores
- Robustness of plagiarism detection mechanism
- Database


Objectives:
The primary objective of this project is to enhance the baseline system with missing features to meet the needs of educational institutions and improve the overall user experience. This includes improving accuracy, transparency, and scalability while ensuring user-friendliness.

Key Goals:
- Implement comprehensive admin management features.
- Enhance the grading system's accuracy and transparency.
- Improving robustness of current plagiarism detection and duplicate submission handling.
- Improve system scalability and performance for large institutions.

Strategy [phases are not sequential]:
- Phase 1: Requirements Gathering and Analysis -> At the moment, we have a general understanding of the system's current limitation, more comprehensive analysis will need to be done by week 3 in order to better define the scope of the project.
- Phase 2: Enhancing the system -> We will collaborate to implement enhanced administration features, optimize the existing grading and plagiarism detection mechanisms, improve system performance, and integrate a more suitable database for the application.
- Phase 3: Testing and QA -> As we work on improving the system, we will explore use cases and leverage different tools to ensure that reliability, usability, and overall quality of the system.


Team Members
Francis Chianu - 666560
Yanet Niguse - 670530
David Gatwal - 666628

Roles:
- Team Lead: Project planning, progress tracking, and coordination
- Backend Developer: Enhancing the systemâ€™s core functionality, including LLM integration and plagiarism detection mechanism.
- Frontend Developer: Implementing the user interface to support the admin management features. Ensure data persistence across pages.
- Tester: Designing test cases to ensure the system reliability and usability.


Stakeholders:
Educators
- General Needs: Accurate grading, reduced workload, and easy-to-use admin features
Students
- General Needs: Transparent, fair and flexible grading, especially in the event that re-evaluation of scores is necessary.
Institution:
- General Needs: Scalable system
